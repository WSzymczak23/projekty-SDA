{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Hate_speech_zadanie.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WSzymczak23/projekty-SDA/blob/main/Copy_of_Copy_of_Hate_speech_zadanie.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DahqWQArOtlb"
      },
      "source": [
        "# Instalacja i import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4uwynfHHCaa"
      },
      "source": [
        "!pip install spacy==3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPIMsAEUG_a9"
      },
      "source": [
        "!python -m spacy download pl_core_news_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvukEZfgE2S6"
      },
      "source": [
        "import keras\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "from keras_preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "\n",
        "nlp = spacy.load(\"pl_core_news_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sQfqnYxO7ow"
      },
      "source": [
        "# Ściąganie i rozpakowanie danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69QIHPvLEr4Q"
      },
      "source": [
        "# get dataset\n",
        "!wget http://2019.poleval.pl/task6/task_6-1.zip\n",
        "!unzip task_6-1.zip\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4mtMlKdO_Wn"
      },
      "source": [
        "# Rozpakowanie danych, preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKzlBnQzFUfk"
      },
      "source": [
        "with open('/content/training_set_clean_only_text.txt', 'r') as data_file:\n",
        "  raw_data = data_file.read()\n",
        "\n",
        "with open('/content/training_set_clean_only_tags.txt', 'r') as label_file:\n",
        "  raw_labels = label_file.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VV_oecwLY-x"
      },
      "source": [
        "nlabels = np.array([int(x) if x != '' else 0 for x in raw_labels.split('\\n') ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAKs6-CNFhW8"
      },
      "source": [
        "text_corpus =  raw_data\n",
        "\n",
        "lemmantized_text = []\n",
        "\n",
        "for tweet in tqdm(text_corpus):\n",
        "  doc = nlp(tweet)\n",
        "  doc_lemmantized = []\n",
        "  for x in doc:\n",
        "    if x.is_stop == False and x.is_punct == False:\n",
        "      doc_lemmantized.append(x.lemma_)\n",
        "  lemmantized_text.append(doc_lemmantized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWsH03L4PIIW"
      },
      "source": [
        "# Przygotowanie tensorów"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnuH2bpnFioS"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLIDS-IqFsIu"
      },
      "source": [
        "tokenizer.fit_on_texts(lemmantized_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpdi8ewpFz2J"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(lemmantized_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDfZcIa3GUuN"
      },
      "source": [
        "padded = pad_sequences(sequences, maxlen=XXX)\n",
        "padded.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5PmFRswGoiI"
      },
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "\n",
        "model.add(layers.GRU(32, input_shape=(None, float_data.shape[-1])))\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer=RMSprop(), loss='mae')\n",
        "history = model.fit_generator(train_gen_reverse,\n",
        "                              steps_per_epoch=500,\n",
        "                              epochs=20,\n",
        "                              validation_data=val_gen_reverse,\n",
        "                              validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_E0vSIeGroy"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GJRfrXtMnJe"
      },
      "source": [
        "model.compile( # ???)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VUftdVWLJOa"
      },
      "source": [
        "model.fit(padded, labels, epochs=5, batch_size=32, validation_split=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIEA9hN9Mh7K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}